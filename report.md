# AI와 테스트를 활용한 안정적인 기능 개발 리포트

## 사용하는 도구를 선택한 이유가 있을까요? 각 도구의 특징에 대해 조사해본적이 있나요?

모르는 개념 정리와 아이디에이션에는 chatGPT를 에이전트의 룰과 폴더구조를 디벨롭하는데는 Cursor IDE를 실제 에이전트 구동과 과제 구현은 Claude Code를 사용했습니다.
보편적인 성능과 멀티모달 스러운 기능들은 chatGPT가 좋고 Cursor는 열려있는 프로젝트를 인덱싱하고 IDE내에서 여러가지 컨텍스트를 쉽게 전달할 수 있어 편리하다고 알고 있습니다. 그리고 클로드 코드는 코드 에이전트로서 능력이 다른 LLM모델에 비해 우수한 편이라고 알고 있습니다.

이곳 저곳에서 흐르는 이야기들을 모아서 각 도구의 특징을 어렴풋이 알고 있으나, 직접 '조사'해본 적은 없어 확실하진 않습니다.

## 테스트를 기반으로 하는 AI를 통한 기능 개발과 없을 때의 기능개발은 차이가 있었나요?

테스트 없이 AI기능 개발을 할 때엔 그 결과에 대한 신뢰가 부족했습니다. AI가 생성한 코드를 다시 검토하는 시간이 생각보다 큰 부담으로 다가왔는데
테스트를 기반으로 한다면 초기에 테스트를 AI가 생성해주니까 테스트 설계에도 큰 부담이 없고 이후 GREEN-REFACTOR단계에서 생성되는 코드에 대한 신뢰가 올라가는것이 큰 장점이라고 생각됩니다.

꼭 TDD가 아니더라도 '바이브 엔지니어링'을 시도하는 사람이라면 테스트를 기반으로 기능 개발하는것이 당연한 상식이 되지 않을까 생각됩니다.

## AI의 응답을 개선하기 위해 추가했던 여러 정보(context)는 무엇인가요?

좋은 테스트를 작성하기 위한 방법, TDD 방법론 등 양질의 방법론 문서

/agent-docs 폴더 아래 각 에이전트들이 참고하고 활용할 수 있는 문서들을 남겨놓음

- prompt.md: subagent를 호출할 때 같은 프롬프트 양식으로 작업지시할 수 있게함
- getting-start.md: subagent를 처음 호출하는 사용자를 위한 매뉴얼,
- contract.md: 에이전트가 행동했으면 하는 양식과 인풋 아웃풋 산출 탬프릿이 담겨있는 에이전트 명세서

실행한 산출물의 결과를 리포트로 만들고 다음 작업자에게 넘길 수 있게끔 구성한 handoff 문서

실행 결과를 로그로 남기고 로그를 활용할 수 있게 에이전트 설정

각 문서를 참조할 수 있게 문서 경로를 확실하게 명시

## 이 context를 잘 활용하게 하기 위해 했던 노력이 있나요?

에이전트가 돌아가면서 필요한 때에 산출물에 대한 문서를 생성하고 생성된 문서를 읽어 필요한 컨텍스트를 가져오게끔 명시했습니다.

```text
<@agent-code-writer contract.md 예시>

---

## 입력 계약

### Handoff 문서 경로

.claude/agent-docs/orchestrator/handoff/phase4.md

### 필수 입력 항목

---
phase: 4
agent: code-writer
timestamp: [ISO 8601 형식]
status: ready

inputs:
  failing_tests: |
    [실패하는 테스트 파일 경로 목록]
    - src/__tests__/task.[feature].spec.ts
    - [추가 테스트 파일들]

  test_execution_result: |
    [테스트 실행 결과]
    ✗ 실패한 테스트 목록
    예상 에러 메시지들

  context_files:
    - CLAUDE.md # 프로젝트 규칙
    - .claude/agent-docs/feature-designer/logs/spec.md # 기술 명세서
    - .claude/agent-docs/test-designer/logs/test-strategy.md # 테스트 전략
    - src/types.ts # 타입 정의
    - [구현 대상 파일들]

references:
  agent_definition: ../../agents/code-writer.md
  project_rules: CLAUDE.md
  architecture_guide: .claude/docs/folder-tree.md

output_requirements:
  implementation_files:
    - [생성/수정할 파일 목록]

  log_file: .claude/agent-docs/code-writer/logs/YYYY-MM-DD_implementation-log.md

  validation_proof: |
    - 테스트 통과 증명 (pnpm test 결과)
    - TypeScript 컴파일 성공 (pnpm lint:tsc)

constraints:
  - 최소 구현 (GREEN 단계 철학)
  - 테스트 파일은 절대 수정하지 않음
  - 프로덕션 코드만 작성
  - 반복 일정 기능 구현 금지 (8주차 과제)
  - 전역 상태 라이브러리 사용 금지
  - 순수 함수 원칙 준수 (Utils)

validation_criteria:
  - 모든 테스트가 통과하는가
  - TypeScript 컴파일이 성공하는가
  - CLAUDE.md 규칙을 준수하는가
  - 최소 구현으로 작성되었는가 (과도한 추상화 없음)
---
```

## 생성된 여러 결과는 만족스러웠나요? AI의 응답을 어떤 기준을 갖고 '평가(evaluation)'했나요?

대부분의 생성된 결과는 만족스러웠으나 가끔 실제 작업 결과와는 다른 응답을 줄 때가 있었습니다.

Phase가 끝나면 결과 보고 리포트를 작성하고 그걸 기반으로 진행, 지연 등의 평가를 진행하려 했는데 의도대로 되진 않았던 것 같습니다.
그리고 제가 에이전트를 만드는데 사용한 접근법이 AI의 응답에 대한 평가를 적절한 때에 주기 어려운 구조였습니다.

추후 개선해야하는 시간이 생긴다면 가장 우선 개선해야할 지점이라 생각됩니다.

## AI에게 어떻게 질문하는것이 더 나은 결과를 얻을 수 있었나요? 시도했던 여러 경험을 알려주세요.

AI가 사용했으면, 참고했으면 하는 방법론이나 아키텍처, 프로젝트 구성 등을 먼저 물어봤습니다.
TDD는 어떤 방법론인지, TDD를 잘 해내려면 어떤 프로세스와 점검리스트가 있어야하는지 물어보고 `.claude` 내의 폴더구조와 문서를 보고 분석해달라고 요청했습니다.
그 후 생성된 분석본이나 요약본을 기반으로 원하는 생성물을 요청했습니다.

원하는 생성물에 대한 일종의 작업지시서 역할을 해서 원하는 결과에 더 가까워지는 효과가 있었습니다.

## AI에게 지시하는 작업의 범위를 어떻게 잡았나요? 범위를 좁게, 넓게 해보고 결과를 적어주세요. 그리고 내가 생각하는 적절한 단위를 말해보세요.

TDD를 기반을 각 Phase를 정의했고 이 Phase가 지시하는 작업의 범위였습니다.
Phase단위로 지시해보니 어떤 에이전트는 작업의 범위가 넓고 어떤 에이전트는 작업의 범위가 너무 작았습니다. 태스크를 실행하는데는 작업 범위의 넓고 좁음이 큰 상관이 없지만, 토큰 소모의 효율성을 생각해볼 때 조정할 수 있는 요소라고 생각됩니다.
Phase가 끝나면 깃에 커밋하여 작업의 구분점으로 삼았는데, Phase에서 행해지는 작업이 생각보다 많아 일부 테스트가 잘못되면 그 테스트를 만드는 Phase를 다시 돌려야하는 등 비효율적인 부분이 컸고 실제 문제가 생긴 지점에서 문제를 해결할 수 없음이 치명적이라 생각됩니다.

아마 다시 에이전트를 만든다면 작업의 단위를 조금 더 촘촘하게 잡을 것 같습니다.
다만 작업을 지시할 때마다 컨텍스트를 주입해야하니 토큰의 소모가 더 심해지지 않을까 생각됩니다.

## 동기들에게 공유하고 싶은 좋은 참고자료나 문구가 있었나요? 마음껏 자랑해주세요.

저는 이 영상을 보고 아이디어를 많이 얻었습니다!

- [개발동생 - Claude Code 신기능 Subagents | 멀티 에이전트 + Playwright MCP](https://www.youtube.com/watch?v=u4_AcW96_78&t=1077s)
  - [영상에서 활용된 프로젝트](https://github.com/devbrother2024/memo-app)

## AI가 잘하는 것과 못하는 것에 대해 고민한 적이 있나요? 내가 생각하는 지점에 대해 작성해주세요.

생성은 잘하는데 참고나 활용은 기대만큼 하지 못하는 것 같습니다. 그에 대한 확실한 지침이 있어도 지침을 따르지 않거나 따랐다고 할루시네이션이 나온 경우가 적지 않았습니다.
컨텍스트 유지와 활용에 대한 부분인것 같은데 이른 더 효율적이고 정확하게 할 수 있는 방법을 찾아보려합니다.

물론 LLM이 의도한 대로 작동하는 기계가 아닌 생성모델이기 때문에 적절한 접근법인지는 의심이 됩니다.
PR에도 적었지만, 페르소나를 세밀하게 부여하고 롤플레잉해서 원하는 상황(을 하는 조직)을 시뮬레이션하는게 가장 정답에 가깝지 않을까 생각됩니다.
좀더 알잘딱깔센하게 동작하게끔 만들어보고 싶습니다!

## 마지막으로 느낀점에 대해 적어주세요!

최근 특히 관심이 많던 주제라서 더욱 재밌게 시도하고 해봤던 것 같습니다.
일부러 Claude max로 구독해서 써보고 있는데 역시 많이 써보는게 더 잘 알 수 있는 방법임을 느꼈습니다.
